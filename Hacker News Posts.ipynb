{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final project suggested in the _Python for Data Science: Intermediate_ course hosted by [Dataquest.io](https://www.dataquest.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will analyze two different kinds of posts from the well-known technology webpage [Hacker News](https://news.ycombinator.com/). These two kinds of posts are `Ask HN` and `Show HN`.\n",
    "\n",
    "People submit `Ask HN` posts to ask the community a specific tech-related question. On the other hand, `Show HN` ones are those in which people share projects, products or anything they find interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare these posts to answer the following questions:\n",
    "\n",
    "- Do `Ask HN` or `Show HN` posts receive more comments?\n",
    "- At what time do these posts receive the most comments on average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we will use a [data set](https://www.kaggle.com/hacker-news/hacker-news-posts) from [Kaggle.com](https://www.kaggle.com/).\n",
    "This data set contains Hacker News posts from September 2015 to September 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we'll read the data, separate the headers and have a look at the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293119\n",
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['12579008',\n",
       "  'You have two days to comment if you want stem cells to be classified as your own',\n",
       "  'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018',\n",
       "  '1',\n",
       "  '0',\n",
       "  'altstar',\n",
       "  '9/26/2016 3:26'],\n",
       " ['12579005',\n",
       "  'SQLAR  the SQLite Archiver',\n",
       "  'https://www.sqlite.org/sqlar/doc/trunk/README.md',\n",
       "  '1',\n",
       "  '0',\n",
       "  'blacksqr',\n",
       "  '9/26/2016 3:24'],\n",
       " ['12578997',\n",
       "  'What if we just printed a flatscreen television on the side of our boxes?',\n",
       "  'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43',\n",
       "  '1',\n",
       "  '0',\n",
       "  'pavel_lishin',\n",
       "  '9/26/2016 3:19'],\n",
       " ['12578989',\n",
       "  'algorithmic music',\n",
       "  'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext',\n",
       "  '1',\n",
       "  '0',\n",
       "  'poindontcare',\n",
       "  '9/26/2016 3:16'],\n",
       " ['12578979',\n",
       "  'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake',\n",
       "  'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94',\n",
       "  '1',\n",
       "  '0',\n",
       "  'markgainor1',\n",
       "  '9/26/2016 3:14']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "opened_file = open('HN_posts_year_to_Sep_26_2016.csv', encoding='utf8')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(len(hn))\n",
    "print(headers)\n",
    "hn[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this data set contains the title, url and author of the posts, as well as more interesting information for our project, such as number of comments and date of creation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only want to analyze `Ask HN` and `Show HN` posts, we will separate the two of them from the rest. For that, we will search for posts that begin with those strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ask HN posts:    9139\n",
      "Number of Show HN posts:   10158\n",
      "Number of posts not used:  273822\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for post in hn:\n",
    "    title = post[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(post)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(post)\n",
    "    else:\n",
    "        other_posts.append(post)\n",
    "        \n",
    "print(\"Number of Ask HN posts:   \", len(ask_posts))\n",
    "print(\"Number of Show HN posts:  \", len(show_posts))\n",
    "print(\"Number of posts not used: \", len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even though the `lower()` and `startswith()` methods are useful, we could also use regex to find these posts.\n",
    "To do so, we match any title that starts with either _ask hn_ or _show hn_, using case insensitive matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ask HN posts:    9139\n",
      "Number of Show HN posts:   10158\n",
      "Number of posts not used:  273822\n"
     ]
    }
   ],
   "source": [
    "# import the regex module\n",
    "import re\n",
    "\n",
    "# our regex to find Ask HN posts\n",
    "regex_ask = r\"^ask\\shn\"\n",
    "\n",
    "# our regex to find Show HN posts\n",
    "regex_show = r\"^show\\shn\"\n",
    "\n",
    "ask_posts_re = []\n",
    "show_posts_re = []\n",
    "other_posts_re = []\n",
    "\n",
    "for post in hn:\n",
    "    title = post[1]\n",
    "    if re.search(regex_ask, title, re.IGNORECASE):\n",
    "        ask_posts_re.append(post)\n",
    "    elif re.search(regex_show, title, re.IGNORECASE):\n",
    "        show_posts_re.append(post)\n",
    "    else:\n",
    "        other_posts_re.append(post)\n",
    "        \n",
    "print(\"Number of Ask HN posts:   \", len(ask_posts_re))\n",
    "print(\"Number of Show HN posts:  \", len(show_posts_re))\n",
    "print(\"Number of posts not used: \", len(other_posts_re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that we get the same output using both methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Average Number of Comments for Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can calculate the number of comments for both types of posts on average, and therefore, answer our first question of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of comments in Ask HN posts:  10.393478498741656\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for post in ask_posts:\n",
    "    comments = int(post[4])\n",
    "    total_ask_comments += comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(\"Average number of comments in Ask HN posts: \", avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of comments in Show HN posts:  4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "\n",
    "for post in show_posts:\n",
    "    comments = int(post[4])\n",
    "    total_show_comments += comments\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(\"Average number of comments in Show HN posts: \", avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, on average, `Ask HN` posts get more or less two times the amount of comments than `Show HN` ones.\n",
    "\n",
    "For now on, we will only analyze these posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Amount of Ask HN Posts and Comments by Hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will start working with dates and times, using the `datetime` module, to find the amount of Ask HN posts and comments by hour.\n",
    "\n",
    "We will create two dictionaries, one containing the number of posts by hour and another one containing the number of comments each hour, using the proper date and time formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for post in ask_posts:\n",
    "    post_list = [post[6], int(post[4])]\n",
    "    result_list.append(post_list)\n",
    "    \n",
    "posts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    comments = row[1]\n",
    "    hour = dt.datetime.strptime(date, date_format).strftime(\"%H\")\n",
    "    \n",
    "    if hour not in posts_by_hour:\n",
    "        posts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comments\n",
    "    else:\n",
    "        posts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the total number of comments each hour, to get a general idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'02': 2996,\n",
       " '01': 2089,\n",
       " '22': 3372,\n",
       " '21': 4500,\n",
       " '19': 3954,\n",
       " '17': 5547,\n",
       " '15': 18525,\n",
       " '14': 4972,\n",
       " '13': 7245,\n",
       " '11': 2797,\n",
       " '10': 3013,\n",
       " '09': 1477,\n",
       " '07': 1585,\n",
       " '03': 2154,\n",
       " '23': 2297,\n",
       " '20': 4462,\n",
       " '16': 4466,\n",
       " '08': 2362,\n",
       " '00': 2277,\n",
       " '18': 4877,\n",
       " '12': 4234,\n",
       " '04': 2360,\n",
       " '06': 1587,\n",
       " '05': 1838}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Average Number of Comments for Ask HN Posts by Hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get the average number of comments by hour, which we will store in a list of lists for the next step of our porject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['02', 11.137546468401487],\n",
       " ['01', 7.407801418439717],\n",
       " ['22', 8.804177545691905],\n",
       " ['21', 8.687258687258687],\n",
       " ['19', 7.163043478260869],\n",
       " ['17', 9.449744463373083],\n",
       " ['15', 28.676470588235293],\n",
       " ['14', 9.692007797270955],\n",
       " ['13', 16.31756756756757],\n",
       " ['11', 8.96474358974359],\n",
       " ['10', 10.684397163120567],\n",
       " ['09', 6.653153153153153],\n",
       " ['07', 7.013274336283186],\n",
       " ['03', 7.948339483394834],\n",
       " ['23', 6.696793002915452],\n",
       " ['20', 8.749019607843136],\n",
       " ['16', 7.713298791018998],\n",
       " ['08', 9.190661478599221],\n",
       " ['00', 7.5647840531561465],\n",
       " ['18', 7.94299674267101],\n",
       " ['12', 12.380116959064328],\n",
       " ['04', 9.7119341563786],\n",
       " ['06', 6.782051282051282],\n",
       " ['05', 8.794258373205741]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    avg = comments_by_hour[hour] / posts_by_hour[hour]\n",
    "    avg_by_hour.append([hour, avg])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and Printing Values from a List of Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better reading and a cleaner look, let's sort the results and swap the columns of the list of lists, so we can see in which hours Ask HN posts got more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[28.676470588235293, '15'],\n",
       " [16.31756756756757, '13'],\n",
       " [12.380116959064328, '12'],\n",
       " [11.137546468401487, '02'],\n",
       " [10.684397163120567, '10'],\n",
       " [9.7119341563786, '04'],\n",
       " [9.692007797270955, '14'],\n",
       " [9.449744463373083, '17'],\n",
       " [9.190661478599221, '08'],\n",
       " [8.96474358974359, '11'],\n",
       " [8.804177545691905, '22'],\n",
       " [8.794258373205741, '05'],\n",
       " [8.749019607843136, '20'],\n",
       " [8.687258687258687, '21'],\n",
       " [7.948339483394834, '03'],\n",
       " [7.94299674267101, '18'],\n",
       " [7.713298791018998, '16'],\n",
       " [7.5647840531561465, '00'],\n",
       " [7.407801418439717, '01'],\n",
       " [7.163043478260869, '19'],\n",
       " [7.013274336283186, '07'],\n",
       " [6.782051282051282, '06'],\n",
       " [6.696793002915452, '23'],\n",
       " [6.653153153153153, '09']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, we will print a top 5 in a cleaner way. Looking into the [documentation of the data set](https://www.kaggle.com/hacker-news/hacker-news-posts), we can see that the time zone used is Eastern Time in the US (EST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "At 15:00 EST, 28.68 average comments per post.\n",
      "At 13:00 EST, 16.32 average comments per post.\n",
      "At 12:00 EST, 12.38 average comments per post.\n",
      "At 02:00 EST, 11.14 average comments per post.\n",
      "At 10:00 EST, 10.68 average comments per post.\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "string_format = \"At {} EST, {:.2f} average comments per post.\"\n",
    "for avg, hour in sorted_swap[:5]:\n",
    "    print(string_format.format(dt.datetime.strptime(hour, \"%H\").strftime(\"%H:%M\"), avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we analyzed data about two different kinds of posts in Hacker News, `Ask HN`, and `Show HN`, to determine which posts and what times get the most comments on average. In our analysis we found out that to maximize the comments received, we recommend posting Ask HN entries at 15:00 EST."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
